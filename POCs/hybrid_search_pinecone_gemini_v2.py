import os
import re
import google.generativeai as genai
from pinecone import Pinecone
from langchain.vectorstores import Pinecone as PineconeVectorStore
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv  # Load environment variables

# ‚úÖ Load .env file
load_dotenv(dotenv_path="POCs/.env")

# ‚úÖ Load API Keys
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
PINECONE_API_KEY = os.getenv("PINECONE_API_KEY")

# ‚úÖ Ensure API Key is Set
if not GEMINI_API_KEY:
    raise ValueError("‚ùå Gemini API Key is missing! Check .env or set it manually.")

genai.configure(api_key=GEMINI_API_KEY)

# ‚úÖ Extract Quarter from Query
def extract_quarter(query):
    """Extracts quarter and year from the user query using regex."""
    match = re.search(r"(Q[1-4])\s*(\d{4})", query, re.IGNORECASE)
    if match:
        return match.group(1).upper(), match.group(2)  # Returns ("Q3", "2023")
    return None, None

# ‚úÖ Extract Safe Response from Gemini
def extract_gemini_response(response):
    """Extracts text safely from Gemini response."""
    if hasattr(response, "candidates") and response.candidates:
        for candidate in response.candidates:
            if hasattr(candidate, "content") and candidate.content.parts:
                return "".join(part.text for part in candidate.content.parts if hasattr(part, "text"))
    return "No response generated by Gemini."

# ‚úÖ Hybrid Search Function for Gemini
def query_pinecone_with_gemini(query, index_name="json-index", region="us-east-1", top_k=5):
    """ Query Pinecone with hybrid search (semantic + keyword-based) and generate an answer using Gemini. """

    quarter, year = extract_quarter(query)

    # ‚úÖ Initialize Pinecone Client
    pc = Pinecone(api_key=PINECONE_API_KEY)
    index = pc.Index(index_name)
    embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
    vector_store = PineconeVectorStore(index=index, embedding=embeddings, text_key="page_content")
    retriever = vector_store.as_retriever(search_kwargs={"k": top_k})

    # ‚úÖ Perform Hybrid Search
    semantic_results = retriever.get_relevant_documents(query)
    keyword_results = vector_store.similarity_search(query, k=top_k)

    # ‚úÖ Merge & Weight Results (Semantic: 70%, Keyword: 30%)
    ranked_results = [(doc.page_content, 0.7) for doc in semantic_results] + \
                     [(doc.page_content, 0.3) for doc in keyword_results]

    # ‚úÖ Sort & Deduplicate Results
    unique_results = {}
    for content, score in sorted(ranked_results, key=lambda x: x[1], reverse=True):
        unique_results[content] = score  # Ensures highest score is kept

    # ‚úÖ Extract Final Sorted List
    final_results = list(unique_results.keys())[:top_k]

    # ‚úÖ Debugging: Print Retrieved Chunks
    print("üîç Retrieved Chunks (before filtering):", final_results)

    # ‚úÖ Quarter-Year Filtering (Fix: Don't remove all results!)
    if quarter and year:
        pattern = re.compile(rf"{quarter}.*{year}", re.IGNORECASE)
        priority_results = [doc for doc in final_results if pattern.search(doc)]
        final_results = priority_results if priority_results else final_results  # Avoid empty list

    # ‚úÖ Final Debugging
    print("üîç Final Chunks (after filtering):", final_results)

    if not final_results:
        return f"I couldn't find relevant information for {quarter} {year}."

    # ‚úÖ Prepare context for Gemini
    top_chunks = "\n\n".join(final_results[:3])

    # ‚úÖ Generate answer using Gemini
    model = genai.GenerativeModel("gemini-1.5-flash")
    response = model.generate_content(f"""
    You are an AI financial assistant that answers questions based on reports.
    
    Context:
    {top_chunks}
    
    Question: {query}
    
    Answer based on the above context:
    """)

    return extract_gemini_response(response)

# ‚úÖ Example Usage
query_result = query_pinecone_with_gemini("What is the revenue for Q1 2025?")
print("\nüí° Answer:\n", query_result)
