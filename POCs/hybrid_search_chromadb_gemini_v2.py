import os
import re
import google.generativeai as genai
from langchain.vectorstores import Chroma
from langchain.embeddings.huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv  # Load environment variables

# ‚úÖ Load .env file
load_dotenv(dotenv_path="POCs/.env")

# ‚úÖ Load API Keys
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    raise ValueError("‚ùå Gemini API Key is missing! Check .env or set it manually.")

genai.configure(api_key=GEMINI_API_KEY)

# ‚úÖ Function to Extract Quarter from Query
def extract_quarter(query):
    """Extracts quarter and year from the user query using regex."""
    match = re.search(r"(Q[1-4])\s*(\d{4})", query, re.IGNORECASE)
    if match:
        return match.group(1).upper(), match.group(2)  # Returns ("Q3", "2023")
    return None, None

# ‚úÖ Extract Safe Response from Gemini
def extract_gemini_response(response):
    """Extracts text safely from Gemini response."""
    if hasattr(response, "candidates") and response.candidates:
        for candidate in response.candidates:
            if hasattr(candidate, "content") and hasattr(candidate.content, "parts"):
                return "".join(part.text for part in candidate.content.parts if hasattr(part, "text"))
    return "No response generated by Gemini."

# ‚úÖ Hybrid Search Function for ChromaDB
def query_chromadb_with_gemini(query, collection_name="json-index", persist_directory="./chroma_langchain_db", top_k=5):
    """ Query ChromaDB with hybrid search (semantic + keyword-based) and generate an answer using Gemini. """

    quarter, year = extract_quarter(query)

    # ‚úÖ Load ChromaDB
    vector_store = Chroma(
        collection_name=collection_name,
        embedding_function=HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2"),
        persist_directory=persist_directory
    )

    # ‚úÖ Perform Hybrid Search
    semantic_results = vector_store.similarity_search_with_relevance_scores(query, k=top_k)
    keyword_results = vector_store.similarity_search_with_relevance_scores(query, k=top_k)

    # ‚úÖ Merge & Weight Results (Semantic: 70%, Keyword: 30%)
    ranked_results = [(doc.page_content, 0.7 * score) for doc, score in semantic_results] + \
                     [(doc.page_content, 0.3 * score) for doc, score in keyword_results]

    # ‚úÖ Sort & Deduplicate Results
    unique_results = {}
    for content, weighted_score in sorted(ranked_results, key=lambda x: x[1], reverse=True):
        unique_results[content] = weighted_score  # Ensures highest score is kept

    # ‚úÖ Extract Final Sorted List
    final_results = list(unique_results.keys())[:top_k]

    # ‚úÖ Debugging: Print Retrieved Chunks
    print("üîç Retrieved Chunks (before filtering):", final_results)

    # ‚úÖ Quarter-Year Filtering (Fix: Don't remove all results!)
    if quarter and year:
        pattern = re.compile(rf"{quarter}.*{year}", re.IGNORECASE)
        priority_results = [doc for doc in final_results if pattern.search(doc)]
        final_results = priority_results if priority_results else final_results  # Avoid empty list

    # ‚úÖ Final Debugging
    print("üîç Final Chunks (after filtering):", final_results)

    if not final_results:
        return f"I couldn't find relevant information for {quarter} {year}."

    # ‚úÖ Prepare context for Gemini
    top_chunks = "\n\n".join(final_results[:3])

    # ‚úÖ Generate answer using Gemini
    model = genai.GenerativeModel("gemini-1.5-flash")
    response = model.generate_content(f"""
    You are an AI financial assistant that answers questions based on reports.
    
    Context:
    {top_chunks}
    
    Question: {query}
    
    Answer based on the above context:
    """)

    return extract_gemini_response(response)

# ‚úÖ Example Usage
query_result = query_chromadb_with_gemini("What is the revenue for Q1 2025?")
print("\nüí° Answer:\n", query_result)
